{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Importing essential libraries\n",
    "import numpy as np\n",
    "import pandas_ml as pdml\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import math\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Length of train data %d %d', 800)\n",
      "6062\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Getting train data in dataframe\n",
    "trainData = pd.read_csv(\"data/train.dat\",sep='\\t',header=None,names=[\"active\",\"features\"])\n",
    "print('Length of train data %d %d', len(trainData));\n",
    "\n",
    "X_train = pd.DataFrame(trainData['features']);\n",
    "Y_train = pd.DataFrame(trainData['active']);\n",
    "\n",
    "split = lambda x: pd.Series([i for i in (x.split(' '))])\n",
    "X_train = X_train['features'].apply(split);\n",
    "\n",
    "for col in range(0,len(X_train.columns)):\n",
    "    X_train[col] = pd.to_numeric(X_train[col], errors='coerce', downcast='integer')\n",
    "\n",
    "X_train = X_train.fillna(0);\n",
    "\n",
    "input_cols = len(X_train.columns);\n",
    "print(input_cols);\n",
    "max_col = int(X_train.values.max())+1;\n",
    "max_row = int(len(X_train));\n",
    "\n",
    "matrix = [[0 for col in range(max_col)] for row in range(max_row)]\n",
    "\n",
    "for row in range(0, len(X_train)-1):\n",
    "    for col in range(0,input_cols-1):\n",
    "        colIndex = X_train[col][row];\n",
    "        if(colIndex!=0):\n",
    "            matrix[row][int(colIndex)] = 1;\n",
    "X = pd.DataFrame(matrix);\n",
    "print(type(X))\n",
    "y = Y_train\n",
    "# Construct the matrix\n",
    "\n",
    "\n",
    "# df_majority = pd.DataFrame(trainData[trainData.active==0])\n",
    "# df_minority = pd.DataFrame(trainData[trainData.active==1])\n",
    "\n",
    "# print('Majority class rows ', len(df_majority))\n",
    "# print('Minority class rows ', len(df_minority))\n",
    "\n",
    "# # Upsampling the minority class\n",
    "# df_minority_upsampled = resample(df_minority, replace=True, n_samples=722, random_state=123)\n",
    "\n",
    "# # Combine the resampled minority and majority samples\n",
    "# df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# y = df_upsampled.active\n",
    "# X = df_upsampled.drop('active', axis=1)\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=100001, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applying Dimesionality Reduction\n",
    "from sklearn.decomposition import SparsePCA\n",
    "pca = SparsePCA(n_components=100)\n",
    "\n",
    "X = pca.fit_transform(X);\n",
    "print(X);\n",
    "\n",
    "# from imblearn.combine import SMOTEENN\n",
    "# # Apply SMOTE + ENN\n",
    "# sm = SMOTEENN()\n",
    "# X_resampled, y_resampled = sm.fit_sample(X, y)\n",
    "# X_res_vis = pca.transform(X_resampled)\n",
    "# print(X_res_vis);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying Dimesionality Reduction on test\n",
    "testData = pd.read_csv(\"data/test.dat\",sep='\\t',header=None,names=[\"features\"])\n",
    "dfTest = pd.DataFrame(testData);\n",
    "\n",
    "split = lambda x: pd.Series([i for i in (x.split(' '))])\n",
    "X_test = X_test['features'].apply(split);\n",
    "\n",
    "for col in range(0,len(X_test.columns)):\n",
    "    X_test[col] = pd.to_numeric(X_test[col], errors='coerce', downcast='integer')\n",
    "\n",
    "X_test = X_test.fillna(0);\n",
    "\n",
    "input_cols_test = len(X_test.columns);\n",
    "print(input_cols_test);\n",
    "max_col_test = int(X_test.values.max())+1;\n",
    "max_row_test = int(len(X_test));\n",
    "\n",
    "testMatrix = [[0 for col in range(max_col_test)] for row in range(max_row_test)]\n",
    "\n",
    "for row in range(0, len(X_test)-1):\n",
    "    for col in range(0,input_cols_test-1):\n",
    "        colIndex = X_train[col][row];\n",
    "        if(colIndex!=0):\n",
    "            testMatrix[row][int(colIndex)] = 1;\n",
    "X_test = pd.DataFrame(testMatrix);\n",
    "print(type(X_test))\n",
    "\n",
    "X_test = pca.transform(X_test);\n",
    "\n",
    "print(X_test);\n",
    "\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "clf.feature_importances_\n",
    "\n",
    "predication = []\n",
    "\n",
    "prediction = clf.predict(X_test)\n",
    "print(len(prediction))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y.values.ravel())\n",
    "clf.feature_importances_\n",
    "\n",
    "predication = []\n",
    "\n",
    "prediction = clf.predict(X_test)\n",
    "print(len(prediction))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# write the predictions in file\n",
    "output_file = open('data/out_sparsePCA_ExtraTressClassifier.dat', 'w')\n",
    "row_count = 0\n",
    "one_count = 0\n",
    "\n",
    "for n in prediction:\n",
    "    if n == 1:\n",
    "        one_count+=1\n",
    "        output_file.write('1\\n')\n",
    "    else:\n",
    "        output_file.write('0\\n')\n",
    "    row_count+=1\n",
    "    \n",
    "print(row_count)\n",
    "print(one_count)\n",
    "output_file.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/out_sparsePCA_ExtraTressClassifier.dat\", \"r\") as output:\n",
    "    output_data_lines = output.readlines()\n",
    "print(len(output_data_lines))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
