{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "import numpy as np\n",
    "import pandas_ml as pdml\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Length of train data %d %d', 800)\n",
      "6062\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Getting train data in dataframe\n",
    "trainData = pd.read_csv(\"data/train.dat\",sep='\\t',header=None,names=[\"active\",\"features\"])\n",
    "print('Length of train data %d %d', len(trainData));\n",
    "\n",
    "X_train = pd.DataFrame(trainData['features']);\n",
    "Y_train = pd.DataFrame(trainData['active']);\n",
    "\n",
    "split = lambda x: pd.Series([i for i in (x.split(' '))])\n",
    "X_train = X_train['features'].apply(split);\n",
    "\n",
    "for col in range(0,len(X_train.columns)):\n",
    "    X_train[col] = pd.to_numeric(X_train[col], errors='coerce', downcast='integer')\n",
    "\n",
    "X_train = X_train.fillna(0);\n",
    "\n",
    "input_cols = len(X_train.columns);\n",
    "print(input_cols);\n",
    "max_col = int(X_train.values.max())+1;\n",
    "max_row = int(len(X_train));\n",
    "\n",
    "matrix = [[0 for col in range(max_col)] for row in range(max_row)]\n",
    "\n",
    "for row in range(0, len(X_train)-1):\n",
    "    for col in range(0,input_cols-1):\n",
    "        colIndex = X_train[col][row];\n",
    "        if(colIndex!=0):\n",
    "            matrix[row][int(colIndex)] = 1;\n",
    "X = pd.DataFrame(matrix);\n",
    "print(type(X))\n",
    "y = Y_train\n",
    "# Construct the matrix\n",
    "\n",
    "\n",
    "# df_majority = pd.DataFrame(trainData[trainData.active==0])\n",
    "# df_minority = pd.DataFrame(trainData[trainData.active==1])\n",
    "\n",
    "# print('Majority class rows ', len(df_majority))\n",
    "# print('Minority class rows ', len(df_minority))\n",
    "\n",
    "# # Upsampling the minority class\n",
    "# df_minority_upsampled = resample(df_minority, replace=True, n_samples=722, random_state=123)\n",
    "\n",
    "# # Combine the resampled minority and majority samples\n",
    "# df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# y = df_upsampled.active\n",
    "# X = df_upsampled.drop('active', axis=1)\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=100001, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.72293858e-02   6.71597711e-04  -1.07534707e-03 ...,   1.76642895e-03\n",
      "    3.00462281e-02   2.42772878e-03]\n",
      " [  1.83852297e-02  -1.49532806e-04  -9.82659879e-05 ...,   2.24087308e-03\n",
      "    3.80868649e-02   9.68995560e-04]\n",
      " [  2.66322562e-02  -4.37953227e-06  -9.04856280e-05 ...,   2.58360383e-03\n",
      "    6.10285108e-03   2.45504601e-03]\n",
      " ..., \n",
      " [  2.48854900e-02  -3.13798773e-03   4.07840560e-02 ...,   2.70127279e-03\n",
      "   -4.70023709e-04   3.29396949e-03]\n",
      " [  4.16579689e-02  -7.81048565e-04   1.49073831e-04 ...,   2.28114039e-03\n",
      "   -1.97087966e-03  -5.62696999e-02]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Applying Dimesionality Reduction\n",
    "from sklearn.decomposition import SparsePCA\n",
    "pca = SparsePCA(n_components=100)\n",
    "\n",
    "# print(X);\n",
    "# split = lambda x: pd.Series([i for i in (x.split(' '))])\n",
    "# X = X['features'].apply(split)\n",
    "# print(X);\n",
    "# X = X[0:11];\n",
    "\n",
    "# for col in range(0,len(X.columns)):\n",
    "#     X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "# X = X.fillna(0)\n",
    "X = pca.fit_transform(X);\n",
    "print(X);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4858\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[  7.26145328e-02   7.31463734e-03  -1.66804249e-03 ...,   2.64560787e-03\n",
      "    4.52461379e-02   3.56768452e-03]\n",
      " [  2.82670385e-02  -1.62862116e-03  -1.52426921e-04 ...,   3.35619017e-03\n",
      "    5.73544053e-02   1.42399369e-03]\n",
      " [  4.09467285e-02  -4.76992249e-05  -1.40358287e-04 ...,   3.86950330e-03\n",
      "    9.19018657e-03   3.60782874e-03]\n",
      " ..., \n",
      " [  5.75409130e-02  -4.67024178e-03  -7.80217504e-06 ...,   2.53931789e-03\n",
      "   -2.85610753e-03  -8.60310690e-02]\n",
      " [  4.68312106e-02  -4.00079812e-03  -4.69517277e-04 ...,   2.68691732e-03\n",
      "    6.33999028e-02   1.10290572e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "350\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Applying Dimesionality Reduction on test\n",
    "testData = pd.read_csv(\"data/test.dat\",sep='\\t',header=None,names=[\"features\"])\n",
    "dfTest = pd.DataFrame(testData);\n",
    "\n",
    "split = lambda x: pd.Series([i for i in (x.split(' '))])\n",
    "X_test = dfTest['features'].apply(split);\n",
    "\n",
    "for col in range(0,len(X_test.columns)):\n",
    "    X_test[col] = pd.to_numeric(X_test[col], errors='coerce', downcast='integer')\n",
    "\n",
    "X_test = X_test.fillna(0);\n",
    "\n",
    "input_cols_test = len(X_test.columns);\n",
    "print(input_cols_test);\n",
    "max_col_test = int(X_test.values.max())+1;\n",
    "max_row_test = int(len(X_test));\n",
    "\n",
    "testMatrix = [[0 for col in range(max_col_test)] for row in range(max_row_test)]\n",
    "\n",
    "for row in range(0, len(X_test)-1):\n",
    "    for col in range(0,input_cols_test-1):\n",
    "        colIndex = X_train[col][row];\n",
    "        if(colIndex!=0):\n",
    "            testMatrix[row][int(colIndex)] = 1;\n",
    "X_test = pd.DataFrame(testMatrix);\n",
    "print(type(X_test))\n",
    "\n",
    "X_test = pca.transform(X_test);\n",
    "\n",
    "print(X_test);\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron()\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "predication = []\n",
    "\n",
    "prediction = clf.predict(X_test)\n",
    "print(len(prediction))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write the predictions in file\n",
    "output_file = open('data/out_sparsePCA_Perceptron.dat', 'w')\n",
    "row_count = 0\n",
    "one_count = 0\n",
    "\n",
    "for n in prediction:\n",
    "    if n == 1:\n",
    "        one_count+=1\n",
    "        output_file.write('1\\n')\n",
    "    else:\n",
    "        output_file.write('0\\n')\n",
    "    row_count+=1\n",
    "    \n",
    "print(row_count)\n",
    "print(one_count)\n",
    "output_file.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/out_sparsePCA_Perceptron.dat\", \"r\") as output:\n",
    "    output_data_lines = output.readlines()\n",
    "print(len(output_data_lines))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
