{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "import numpy as np\n",
    "import pandas_ml as pdml\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Length of train data %d %d', 800)\n",
      "6062\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Getting train data in dataframe\n",
    "trainData = pd.read_csv(\"data/train.dat\",sep='\\t',header=None,names=[\"active\",\"features\"])\n",
    "print('Length of train data %d %d', len(trainData));\n",
    "\n",
    "X_train = pd.DataFrame(trainData['features']);\n",
    "Y_train = pd.DataFrame(trainData['active']);\n",
    "\n",
    "split = lambda x: pd.Series([i for i in (x.split(' '))])\n",
    "X_train = X_train['features'].apply(split);\n",
    "\n",
    "for col in range(0,len(X_train.columns)):\n",
    "    X_train[col] = pd.to_numeric(X_train[col], errors='coerce', downcast='integer')\n",
    "\n",
    "X_train = X_train.fillna(0);\n",
    "\n",
    "input_cols = len(X_train.columns);\n",
    "print(input_cols);\n",
    "max_col = int(X_train.values.max())+1;\n",
    "max_row = int(len(X_train));\n",
    "\n",
    "matrix = [[0 for col in range(max_col)] for row in range(max_row)]\n",
    "\n",
    "for row in range(0, len(X_train)-1):\n",
    "    for col in range(0,input_cols-1):\n",
    "        colIndex = X_train[col][row];\n",
    "        if(colIndex!=0):\n",
    "            matrix[row][int(colIndex)] = 1;\n",
    "X = pd.DataFrame(matrix);\n",
    "print(type(X))\n",
    "y = Y_train\n",
    "# Construct the matrix\n",
    "\n",
    "\n",
    "# df_majority = pd.DataFrame(trainData[trainData.active==0])\n",
    "# df_minority = pd.DataFrame(trainData[trainData.active==1])\n",
    "\n",
    "# print('Majority class rows ', len(df_majority))\n",
    "# print('Minority class rows ', len(df_minority))\n",
    "\n",
    "# # Upsampling the minority class\n",
    "# df_minority_upsampled = resample(df_minority, replace=True, n_samples=722, random_state=123)\n",
    "\n",
    "# # Combine the resampled minority and majority samples\n",
    "# df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# y = df_upsampled.active\n",
    "# X = df_upsampled.drop('active', axis=1)\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=100001, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -7.20812473e-04   6.53789169e-04  -1.02943854e-03 ...,   2.92458982e-03\n",
      "    3.15408984e-02   1.74027951e-03]\n",
      " [  9.35859404e-04  -7.21936401e-05  -2.22008736e-05 ...,   2.45531939e-03\n",
      "    3.35486639e-02   7.72675583e-04]\n",
      " [  2.57524400e-03   2.42031480e-05  -5.56666710e-05 ...,   2.22066781e-03\n",
      "    6.75642878e-03   2.50765666e-03]\n",
      " ..., \n",
      " [  6.16302018e-02  -3.27782603e-03   4.05622036e-02 ...,   2.01348154e-03\n",
      "   -2.34725244e-03   3.11026829e-03]\n",
      " [ -6.59124133e-04  -7.78177334e-04   2.08492199e-04 ...,   2.89278894e-03\n",
      "   -3.58474262e-03  -5.80052915e-02]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Applying Dimesionality Reduction\n",
    "from sklearn.decomposition import SparsePCA\n",
    "pca = SparsePCA(n_components=100)\n",
    "\n",
    "# print(X);\n",
    "# split = lambda x: pd.Series([i for i in (x.split(' '))])\n",
    "# X = X['features'].apply(split)\n",
    "# print(X);\n",
    "# X = X[0:11];\n",
    "\n",
    "# for col in range(0,len(X.columns)):\n",
    "#     X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "# X = X.fillna(0)\n",
    "X = pca.fit_transform(X);\n",
    "print(X);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4858\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[ -1.12492496e-03   7.13519400e-03  -1.59687150e-03 ...,   4.38191097e-03\n",
      "    4.76963381e-02   2.55734448e-03]\n",
      " [  1.46053466e-03  -7.87892569e-04  -3.44381339e-05 ...,   3.67880340e-03\n",
      "    5.07324932e-02   1.13544843e-03]\n",
      " [  4.01901517e-03   2.64143496e-04  -8.63504877e-05 ...,   3.32722509e-03\n",
      "    1.02171126e-02   3.68500685e-03]\n",
      " ..., \n",
      " [  9.54564410e-02  -5.32137116e-03  -9.78466074e-07 ...,  -5.20704192e-04\n",
      "   -6.69014461e-03  -8.50603621e-02]\n",
      " [  9.91542197e-05  -3.39078529e-03  -4.99598157e-04 ...,   3.53042244e-03\n",
      "    7.02540013e-02   1.93478447e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meenakshiparyani/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:36: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Applying Dimesionality Reduction on test\n",
    "testData = pd.read_csv(\"data/test.dat\",sep='\\t',header=None,names=[\"features\"])\n",
    "dfTest = pd.DataFrame(testData);\n",
    "\n",
    "split = lambda x: pd.Series([i for i in (x.split(' '))])\n",
    "X_test = dfTest['features'].apply(split);\n",
    "\n",
    "for col in range(0,len(X_test.columns)):\n",
    "    X_test[col] = pd.to_numeric(X_test[col], errors='coerce', downcast='integer')\n",
    "\n",
    "X_test = X_test.fillna(0);\n",
    "\n",
    "input_cols_test = len(X_test.columns);\n",
    "print(input_cols_test);\n",
    "max_col_test = int(X_test.values.max())+1;\n",
    "max_row_test = int(len(X_test));\n",
    "\n",
    "testMatrix = [[0 for col in range(max_col_test)] for row in range(max_row_test)]\n",
    "\n",
    "for row in range(0, len(X_test)-1):\n",
    "    for col in range(0,input_cols_test-1):\n",
    "        colIndex = X_train[col][row];\n",
    "        if(colIndex!=0):\n",
    "            testMatrix[row][int(colIndex)] = 1;\n",
    "X_test = pd.DataFrame(testMatrix);\n",
    "print(type(X_test))\n",
    "\n",
    "X_test = pca.transform(X_test);\n",
    "\n",
    "print(X_test);\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=5000)\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "predication = []\n",
    "\n",
    "prediction = clf.predict(X_test)\n",
    "print(len(prediction))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# write the predictions in file\n",
    "output_file = open('data/out_sparsePCA_RandomForestClassifier.dat', 'w')\n",
    "row_count = 0\n",
    "one_count = 0\n",
    "\n",
    "for n in prediction:\n",
    "    if n == 1:\n",
    "        one_count+=1\n",
    "        output_file.write('1\\n')\n",
    "    else:\n",
    "        output_file.write('0\\n')\n",
    "    row_count+=1\n",
    "print(row_count)\n",
    "print(one_count)\n",
    "output_file.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/out_sparsePCA_RandomForestClassifier.dat\", \"r\") as output:\n",
    "    output_data_lines = output.readlines()\n",
    "print(len(output_data_lines))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
